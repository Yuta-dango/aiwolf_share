{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embedding 第一段階"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import openai\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "from embedding import get_embedding as g_e\n",
    "import breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.05039302,  0.00036413,  0.01491035, ..., -0.01889357,\n",
       "        -0.0138039 ,  0.04071731]),\n",
       " array([-0.05649778,  0.00434017,  0.02079348, ..., -0.02294088,\n",
       "        -0.00889205,  0.03463059])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#入力\n",
    "\n",
    "talker = \"Agent[03]\"\n",
    "sentence = \"Agent[00]を占ったら黒だったよ。Agent[01]を占ったら白だったよ。\"\n",
    "brokendown = eval(breakdown.get_list(talker, sentence)) # outputがstrなことがあるから\n",
    "[g_e(sentence) for sentence in brokendown]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Agent[00] is black when checked by Agent[03]',\n",
       " 'Agent[01] is white when checked by Agent[03]']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brokendown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           text                                             vector\n",
      "0  Agent[00] is black when checked by Agent[03]  [-0.05039301514625549, 0.0003641265502665192, ...\n",
      "1  Agent[01] is white when checked by Agent[03]  [-0.05649777501821518, 0.004340166226029396, 0...\n"
     ]
    }
   ],
   "source": [
    "#データセット準備\n",
    "\n",
    "\"\"\"df = pd.read_csv(\"embedded.csv\")←うまくいかない！\"\"\"\n",
    "\n",
    "\n",
    "sentencedf = pd.DataFrame(\n",
    "    {'text': brokendown, 'vector': [g_e(sentence) for sentence in brokendown]}\n",
    "    )\n",
    "print(sentencedf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"protocol_example.csv\")\n",
    "Agents = [\"Agent[00]\", \"Agent[01]\", \"Agent[02]\", \"Agent[03]\", \"Agent[04]\"]\n",
    "Roles = [\"VILLAGER\", \"SEER\", \"MEDIUM\", \"BODYGUARD\", \"WEREWOLF\", \"POSSESSED\"]\n",
    "Teams = [\"BLACK\", \"WHITE\"]\n",
    "\n",
    "datalist = {}\n",
    "for column in df.columns: # \n",
    "    ans = [] # あるカラムのすべての要素\n",
    "    sentences = df[column].dropna().values # .dropna()でnp.nanは落とす\n",
    "    for sentence in sentences:\n",
    "        if \"[AGENT]\" in sentence and \"[ROLE]\" in sentence:\n",
    "            for x in Agents:\n",
    "                for y in Roles:\n",
    "                    ans.append(sentence.replace('[AGENT]', x).replace('[ROLE]', y))\n",
    "        elif \"[AGENT]\" in sentence and \"[TEAM]\" in sentence:\n",
    "            for x in Agents:\n",
    "                for y in Teams:\n",
    "                    ans.append(sentence.replace('[AGENT]', x).replace('[ROLE]', y))\n",
    "        elif \"[AGENT]\" in sentence:\n",
    "            for x in Agents:\n",
    "                ans.append(sentence.replace('[AGENT]', x).replace('[ROLE]', y))\n",
    "        elif '[ROLE]' in sentence:\n",
    "            for y in Roles:\n",
    "                    ans.append(sentence.replace('[AGENT]', x).replace('[ROLE]', y))\n",
    "\n",
    "    datalist[column] = ans\n",
    "    \n",
    "\n",
    "data = []\n",
    "for key, val in (datalist.items()):\n",
    "    for i in val:\n",
    "        data.append([i, key])\n",
    "        \n",
    "Df_all = pd.DataFrame(data, columns=[\"sentence\", \"verb\"])\n",
    "from embedding import get_embedding\n",
    "Df_all[\"embedded\"] = Df_all[\"sentence\"].map(lambda x: get_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一旦、indexを文章にしてdataframeに\n",
    "ans = []\n",
    "for column in df.columns:\n",
    "    for sentence in df[column].dropna().values:\n",
    "        ans.append([sentence, column])\n",
    "\n",
    "Df = pd.DataFrame(ans, columns=[\"sentence\", \"verb\"])\n",
    "\n",
    "from embedding import get_embedding\n",
    "Df[\"embedded\"] = Df[\"sentence\"].map(lambda x: get_embedding(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73 0\n",
      "2 1\n"
     ]
    }
   ],
   "source": [
    "# コサイン類似度の計算\n",
    "from embedding import cos_sim\n",
    "sentencedf[\"most_similar_text\"] = None\n",
    "a=-1\n",
    "for j in sentencedf['vector']:\n",
    "    a=a+1\n",
    "    similarities = []\n",
    "    for i in Df['embedded']:\n",
    "        try:\n",
    "            similarities.append(cos_sim(i, j))\n",
    "            \n",
    "        except:\n",
    "            similarities.append(0)\n",
    "            print(\"error\")\n",
    "    #最も類似しているベクトルに対応するテキストの取得\n",
    "    most_similar_indices = np.argmax(similarities, axis=0)\n",
    "    print(most_similar_indices, a)\n",
    "    \n",
    "    \n",
    "    sentencedf.loc[a, 'most_similar_text'] = Df.loc[most_similar_indices, 'sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>vector</th>\n",
       "      <th>most_similar_text</th>\n",
       "      <th>most_similar_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Agent[00] is black when checked by Agent[03]</td>\n",
       "      <td>[-0.05039301514625549, 0.0003641265502665192, ...</td>\n",
       "      <td>[AGENT] must not be the [ROLE].</td>\n",
       "      <td>My choice is Agent[00].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Agent[01] is white when checked by Agent[03]</td>\n",
       "      <td>[-0.05649777501821518, 0.004340166226029396, 0...</td>\n",
       "      <td>[AGENT] must be the [ROLE].</td>\n",
       "      <td>My choice is Agent[01].</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           text  ...       most_similar_text2\n",
       "0  Agent[00] is black when checked by Agent[03]  ...  My choice is Agent[00].\n",
       "1  Agent[01] is white when checked by Agent[03]  ...  My choice is Agent[01].\n",
       "\n",
       "[2 rows x 4 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencedf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "495 [-0.05039302  0.00036413  0.01491035 ... -0.01889357 -0.0138039\n",
      "  0.04071731]\n",
      "496 [-0.05649778  0.00434017  0.02079348 ... -0.02294088 -0.00889205\n",
      "  0.03463059]\n"
     ]
    }
   ],
   "source": [
    "#試しに全体からembedding\n",
    "sentencedf[\"most_similar_text2\"] = None\n",
    "a=-1\n",
    "for j in sentencedf['vector']:\n",
    "    a=a+1\n",
    "    similarities = []\n",
    "    for i in Df_all['embedded']:\n",
    "        try:\n",
    "            similarities.append(cos_sim(i, j))\n",
    "            \n",
    "            \n",
    "        except:\n",
    "            similarities.append(0)\n",
    "            print(\"error\")\n",
    "    #最も類似しているベクトルに対応するテキストの取得\n",
    "    most_similar_indices = np.argmax(similarities, axis=0)\n",
    "    print(most_similar_indices, j)\n",
    "    \n",
    "    \n",
    "    sentencedf.loc[a, 'most_similar_text2'] = Df_all.loc[most_similar_indices, 'sentence']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
